{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos leer manualmente todos los archivos de la carpeta data\n",
    "df1_2 = pd.read_csv(\"data/data_jan-feb_22.csv\", delimiter = ';' ,on_bad_lines='skip')\n",
    "df3_4 = pd.read_csv(\"data/data_mar-abr_22.csv\", delimiter = ';' ,on_bad_lines='skip')\n",
    "df5_6 = pd.read_csv(\"data/data_may_-_jun_22.csv\", delimiter = ';' ,on_bad_lines='skip')\n",
    "df9_10_11 = pd.read_csv(\"data/data_sep_--_nov_22.csv\", delimiter = ';' ,on_bad_lines='skip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O podemos leerlos de manera automatica con la librería glob que lee los nombres de todos los archivos \n",
    "# contenidos en la carpeta data según la extensión que le especifiquemos\n",
    "filenames = glob.glob('data' + \"/*.csv\")\n",
    "dataframes = []\n",
    "for file in filenames:\n",
    "    dataframes.append(pd.read_csv(file,delimiter = ';' ,on_bad_lines='skip'))\n",
    "# dataframes es una lista de dataframes que contienen los datos de todos los archivos\n",
    "# aqui creamos un dataframe unico con todos los datos\n",
    "df_actual = pd.concat(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si creamos los dataframe de manera manual tenemos esta opción para contatenar\n",
    "# Unimos los archivos\n",
    "# Creamos una lista para almacenar los dataframe\n",
    "df_list = []\n",
    "# Almacenamos todos los Dataframe que se encuentran en el espacio de trabajo que comienzan por df\n",
    "df_list.extend(value for name, value in locals().items() if name.startswith('df'))\n",
    "# Se puede hacer de manera manual: df_list = [df1_2, df3_4, df5_6, df9_10_11]\n",
    "# Se unen todos los dataframe\n",
    "df_actual = pd.concat(df_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pasamos la columna fecha a datetime\n",
    "df_actual['FechaEmiDoc']= pd.to_datetime(df_actual['FechaEmiDoc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora creamos los archivos por mes\n",
    "months = df_actual['FechaEmiDoc'].dt.month.unique()\n",
    "for i in months:\n",
    "    mask = df_actual['FechaEmiDoc'].dt.month == i\n",
    "    df = df_actual[mask]\n",
    "    df.to_csv(f'monthly_data/data_month_{i}.csv', sep=';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
